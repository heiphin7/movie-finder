from fastapi import FastAPI, File, UploadFile
from fastapi.responses import JSONResponse
from pydantic import BaseModel
from typing import Dict
import torch
import httpx
import open_clip
import faiss
import time
from PIL import Image
from io import BytesIO
import numpy as np
import os
import json
import asyncio
from concurrent.futures import ThreadPoolExecutor

executor = ThreadPoolExecutor(max_workers=8)  # –º–æ–∂–Ω–æ –ø–æ–¥—Å—Ç—Ä–æ–∏—Ç—å –ø–æ–¥ CPU


app = FastAPI()

# === –ú–æ–¥–µ–ª—å OpenCLIP ===
device = "cuda" if torch.cuda.is_available() else "cpu"
model, _, preprocess = open_clip.create_model_and_transforms('ViT-B-32', pretrained='laion2b_s34b_b79k')
model = model.to(device)
model.eval()

# === FAISS Index ===
dimension = 512  # –†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å ViT-B-32 —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
faiss_index = faiss.IndexFlatL2(dimension)  # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–æ—Å—Ç–æ–π L2 –∏–Ω–¥–µ–∫—Å
metadata_store = []  # –°–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–∞ -> –º–µ—Ç–∞–¥–∞—Ç–∞

INDEX_PATH = "index.faiss"        # –§–∞–π–ª —Å –∏–Ω–¥–µ–∫—Å–æ–º
META_PATH = "metadata.json"       # –§–∞–π–ª —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏

# –ó–∞–≥—Ä—É–∑–∫–∞ —Å–æ—Ö—Ä–∞–Ω—ë–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
if os.path.exists(INDEX_PATH):
    faiss_index = faiss.read_index(INDEX_PATH)
    print("‚úÖ FAISS –∏–Ω–¥–µ–∫—Å –∑–∞–≥—Ä—É–∂–µ–Ω")

if os.path.exists(META_PATH):
    with open(META_PATH, "r", encoding="utf-8") as f:
        metadata_store = json.load(f)
    print("‚úÖ Metadata –∑–∞–≥—Ä—É–∂–µ–Ω–∞")

# === –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–∞ –∏–∑ –∫–∞—Ä—Ç–∏–Ω–∫–∏ ===
def extract_embedding(image_bytes: bytes):
    image = Image.open(BytesIO(image_bytes)).convert("RGB")
    image_tensor = preprocess(image).unsqueeze(0).to(device)

    with torch.no_grad():
        image_features = model.encode_image(image_tensor)
        image_features = image_features / image_features.norm(dim=-1, keepdim=True)

    return image_features[0].cpu().numpy()


# === /embed: –ø—Ä–æ—Å—Ç–æ –ø–æ–ª—É—á–∏—Ç—å —ç–º–±–µ–¥–¥–∏–Ω–≥ ===
@app.post("/embed")
async def get_embedding(image: UploadFile = File(...)):
    image_bytes = await image.read()
    embedding = extract_embedding(image_bytes)
    return JSONResponse(content={"embedding": embedding.tolist()})


# === /upload: –∑–∞–≥—Ä—É–∑–∫–∞ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏ ===
class UploadPayload(BaseModel):
    data: Dict[str, Dict[str, int]]  # –ø—É—Ç—å -> {–Ω–∞–∑–≤–∞–Ω–∏–µ -> —Ç–∞–π–º–∫–æ–¥}

def batch_process_files(paths_and_metas: list[tuple[str, Dict[str, int]]]):
    embeddings = []
    metas = []

    for path, meta in paths_and_metas:
        try:
            with open(path, "rb") as f:
                image_bytes = f.read()
            image = Image.open(BytesIO(image_bytes)).convert("RGB")
            tensor = preprocess(image).unsqueeze(0)
            embeddings.append(tensor)

            for title, timecode in meta.items():
                metas.append({"title": title, "timecode": timecode})
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ {path}: {e}")

    if not embeddings:
        return

    batch_tensor = torch.cat(embeddings).to(device)

    with torch.no_grad():
        features = model.encode_image(batch_tensor)
        features = features / features.norm(dim=-1, keepdim=True)

    faiss_index.add(features.cpu().numpy())
    metadata_store.extend(metas)
    

async def notify_java(data):
    try:
        async with httpx.AsyncClient() as client:
            java_url = "http://localhost:5720/files/delete"
            await client.post(java_url, json=data, timeout=10)
            print("üì§ –£–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ")
    except Exception as e:
        print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–ø—Ä–∞–≤–∏—Ç—å –∑–∞–ø—Ä–æ—Å –Ω–∞ —É–¥–∞–ª–µ–Ω–∏–µ: {e}")


@app.post("/upload")
async def upload_vectors(data: Dict[str, Dict[str, int]]):
    start = time.time()
    print("üöÄ –ù–∞—á–∞–ª–æ –∑–∞–≥—Ä—É–∑–∫–∏...")

    all_data = list(data.items())
    batch_size = 64
    loop = asyncio.get_running_loop()

    tasks = [
        loop.run_in_executor(executor, batch_process_files, all_data[i:i + batch_size])
        for i in range(0, len(all_data), batch_size)
    ]

    await asyncio.gather(*tasks)

    mid = time.time()
    print(f"‚úÖ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ –∑–∞ {mid - start:.2f} —Å–µ–∫")

    faiss.write_index(faiss_index, INDEX_PATH)
    with open(META_PATH, "w", encoding="utf-8") as f:
        json.dump(metadata_store, f, ensure_ascii=False, indent=2)

    save_time = time.time()
    print(f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ –∑–∞ {save_time - mid:.2f} —Å–µ–∫")

    # –£–≤–µ–¥–æ–º–ª—è–µ–º Java-—Å–µ—Ä–≤–∏—Å –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ, –Ω–æ –Ω–µ –±–ª–æ–∫–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç
    asyncio.create_task(notify_java(data))

    print(f"‚è±Ô∏è –û–±—â–∞—è –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: {time.time() - start:.2f} —Å–µ–∫")
    return {"status": "uploaded", "count": len(metadata_store)}



# === /find: –ø–æ–∏—Å–∫ –ø–æ –∫–∞—Ä—Ç–∏–Ω–∫–µ ===
@app.post("/find")
async def find_image(image: UploadFile = File(...)):
    image_bytes = await image.read()
    embedding = extract_embedding(image_bytes)

    if faiss_index.ntotal == 0:
        return JSONResponse(content={"result": None})

    D, I = faiss_index.search(np.array([embedding]), k=1)
    index = I[0][0]
    distance = D[0][0]

    if index < 0 or distance > 0.5:  # –ü–æ—Ä–æ–≥
        return JSONResponse(content={"result": None})

    meta = metadata_store[index]
    return JSONResponse(content={"result": meta})
